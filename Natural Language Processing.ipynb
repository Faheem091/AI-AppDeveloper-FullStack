{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello there, how are you? Weather is awesome....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hello Mr. Raja, how are you? Weather is aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hello Mr. Raja, how are you. Weather is bad. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"NLP is great technique. It is nice to learn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"AI is making difference in this world now.  I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  \"Hello there, how are you? Weather is awesome....\n",
       "1  \"Hello Mr. Raja, how are you? Weather is aweso...\n",
       "2  \"Hello Mr. Raja, how are you. Weather is bad. ...\n",
       "3  \"NLP is great technique. It is nice to learn t...\n",
       "4  \"AI is making difference in this world now.  I..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('d://data_in.xlsm')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =pd.DataFrame([nltk.sent_tokenize(data['Comment'][0]),\n",
    "nltk.sent_tokenize(data['Comment'][1]),\n",
    "nltk.sent_tokenize(data['Comment'][2]),\n",
    "nltk.sent_tokenize(data['Comment'][3]),\n",
    "nltk.sent_tokenize(data['Comment'][4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv('data_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =pd.DataFrame([nltk.sent_tokenize(data['Comment'][0]),\n",
    "nltk.sent_tokenize(data['Comment'][1]),\n",
    "nltk.sent_tokenize(data['Comment'][2]),\n",
    "nltk.sent_tokenize(data['Comment'][3]),\n",
    "nltk.sent_tokenize(data['Comment'][4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello there, how are you?</td>\n",
       "      <td>Weather is awesome.</td>\n",
       "      <td>Its raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hello Mr. Raja, how are you?</td>\n",
       "      <td>Weather is awesome.</td>\n",
       "      <td>Its raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hello Mr. Raja, how are you.</td>\n",
       "      <td>Weather is bad.</td>\n",
       "      <td>Its heavily raining here now.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"NLP is great technique.</td>\n",
       "      <td>It is nice to learn this technique.\"</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"AI is making difference in this world now.</td>\n",
       "      <td>It would be helpful for betterment of human life.</td>\n",
       "      <td>We need to make advantage of that.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0  \\\n",
       "0                   \"Hello there, how are you?   \n",
       "1                \"Hello Mr. Raja, how are you?   \n",
       "2                \"Hello Mr. Raja, how are you.   \n",
       "3                     \"NLP is great technique.   \n",
       "4  \"AI is making difference in this world now.   \n",
       "\n",
       "                                                   1  \\\n",
       "0                                Weather is awesome.   \n",
       "1                                Weather is awesome.   \n",
       "2                                    Weather is bad.   \n",
       "3               It is nice to learn this technique.\"   \n",
       "4  It would be helpful for betterment of human life.   \n",
       "\n",
       "                                     2  \n",
       "0               Its raining here now.\"  \n",
       "1               Its raining here now.\"  \n",
       "2       Its heavily raining here now.\"  \n",
       "3                                 None  \n",
       "4  We need to make advantage of that.\"  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2. Write a python script that reads the data_in.csv from every cell in columnlabeled as comment and perform word tokenization and redirects in to column of data_out.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Tokenization\n",
    "\n",
    "data2 = pd.DataFrame([nltk.word_tokenize(data['Comment'][0]),\n",
    "nltk.word_tokenize(data['Comment'][1]),\n",
    "nltk.word_tokenize(data['Comment'][2]),\n",
    "nltk.word_tokenize(data['Comment'][3]),\n",
    "nltk.word_tokenize(data['Comment'][4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('data_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>there</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>?</td>\n",
       "      <td>Weather</td>\n",
       "      <td>is</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Raja</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>?</td>\n",
       "      <td>Weather</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>``</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Raja</td>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>.</td>\n",
       "      <td>Weather</td>\n",
       "      <td>...</td>\n",
       "      <td>''</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>``</td>\n",
       "      <td>NLP</td>\n",
       "      <td>is</td>\n",
       "      <td>great</td>\n",
       "      <td>technique</td>\n",
       "      <td>.</td>\n",
       "      <td>It</td>\n",
       "      <td>is</td>\n",
       "      <td>nice</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>``</td>\n",
       "      <td>AI</td>\n",
       "      <td>is</td>\n",
       "      <td>making</td>\n",
       "      <td>difference</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>world</td>\n",
       "      <td>now</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>We</td>\n",
       "      <td>need</td>\n",
       "      <td>to</td>\n",
       "      <td>make</td>\n",
       "      <td>advantage</td>\n",
       "      <td>of</td>\n",
       "      <td>that</td>\n",
       "      <td>.</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2       3           4    5     6      7        8        9   \\\n",
       "0  ``  Hello  there       ,         how  are   you      ?  Weather       is   \n",
       "1  ``  Hello    Mr.    Raja           ,  how   are    you        ?  Weather   \n",
       "2  ``  Hello    Mr.    Raja           ,  how   are    you        .  Weather   \n",
       "3  ``    NLP     is   great   technique    .    It     is     nice       to   \n",
       "4  ``     AI     is  making  difference   in  this  world      now        .   \n",
       "\n",
       "   ...    19    20    21    22    23         24    25    26    27    28  \n",
       "0  ...  None  None  None  None  None       None  None  None  None  None  \n",
       "1  ...  None  None  None  None  None       None  None  None  None  None  \n",
       "2  ...    ''  None  None  None  None       None  None  None  None  None  \n",
       "3  ...  None  None  None  None  None       None  None  None  None  None  \n",
       "4  ...     .    We  need    to  make  advantage    of  that     .    ''  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ex3. From an input file data.txt it is required to identify the POS-Tagging and display it on tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there, how are you? Weather is awesome. Its raining here now.\n",
      "\n",
      "Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\n",
      "\n",
      "Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\n",
      "\n",
      "NLP is great technique. It is nice to learn this technique.\n",
      "\n",
      "AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('d://data.txt') as d:\n",
    "    for line in d:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''Hello there, how are you? Weather is awesome. Its raining here now.\n",
    "\n",
    "Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\n",
    "\n",
    "Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\n",
    "\n",
    "NLP is great technique. It is nice to learn this technique.\n",
    "\n",
    "AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('there', 'RB'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('?', '.'),\n",
       " ('Weather', \"''\"),\n",
       " ('is', 'VBZ'),\n",
       " ('awesome', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Its', 'PRP$'),\n",
       " ('raining', 'VBG'),\n",
       " ('here', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Hello', 'NNP'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Raja', 'NNP'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('?', '.'),\n",
       " ('Weather', \"''\"),\n",
       " ('is', 'VBZ'),\n",
       " ('awesome', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Its', 'PRP$'),\n",
       " ('raining', 'VBG'),\n",
       " ('here', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " ('Hello', 'NNP'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Raja', 'NNP'),\n",
       " (',', ','),\n",
       " ('how', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Weather', 'CC'),\n",
       " ('is', 'VBZ'),\n",
       " ('bad', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Its', 'PRP$'),\n",
       " ('heavily', 'RB'),\n",
       " ('raining', 'VBG'),\n",
       " ('here', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " ('NLP', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('great', 'JJ'),\n",
       " ('technique', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('nice', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('learn', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('technique', 'NN'),\n",
       " ('.', '.'),\n",
       " ('AI', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('making', 'VBG'),\n",
       " ('difference', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('helpful', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('betterment', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('human', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('advantage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentence)\n",
    "tagged = nltk.pos_tag(words)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 4. For a given text file exclude the stop words and perform the Stemming & lemmatization and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "filtered_list = []\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "sentence = \"\"\"Hello there, how are you? Weather is awesome. Its raining here now.\n",
    "\n",
    "Hello Mr. Raja, how are you? Weather is awesome. Its raining here now.\n",
    "\n",
    "Hello Mr. Raja, how are you. Weather is bad. Its heavily raining here now.\n",
    "\n",
    "NLP is great technique. It is nice to learn this technique.\n",
    "\n",
    "AI is making difference in this world now.  It would be helpful for betterment of human life. We need to make advantage of that.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_token = word_tokenize(sentence) \n",
    "\n",
    "filtered_sentence = [w for w in word_token if not w in stop_words] \n",
    "\n",
    "filtered_sentence = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'there', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.', 'Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '?', 'Weather', 'is', 'awesome', '.', 'Its', 'raining', 'here', 'now', '.', 'Hello', 'Mr.', 'Raja', ',', 'how', 'are', 'you', '.', 'Weather', 'is', 'bad', '.', 'Its', 'heavily', 'raining', 'here', 'now', '.', 'NLP', 'is', 'great', 'technique', '.', 'It', 'is', 'nice', 'to', 'learn', 'this', 'technique', '.', 'AI', 'is', 'making', 'difference', 'in', 'this', 'world', 'now', '.', 'It', 'would', 'be', 'helpful', 'for', 'betterment', 'of', 'human', 'life', '.', 'We', 'need', 'to', 'make', 'advantage', 'of', 'that', '.']\n"
     ]
    }
   ],
   "source": [
    "for w in word_token: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "\n",
    "print(word_token)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '.',\n",
       " 'Weather',\n",
       " 'bad',\n",
       " '.',\n",
       " 'Its',\n",
       " 'heavily',\n",
       " 'raining',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'great',\n",
       " 'technique',\n",
       " '.',\n",
       " 'It',\n",
       " 'nice',\n",
       " 'learn',\n",
       " 'technique',\n",
       " '.',\n",
       " 'AI',\n",
       " 'making',\n",
       " 'difference',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'would',\n",
       " 'helpful',\n",
       " 'betterment',\n",
       " 'human',\n",
       " 'life',\n",
       " '.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'make',\n",
       " 'advantage',\n",
       " '.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ex 4. For a given text file exclude the stop words and perform the Stemming & lemmatization and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming for Hello is hello\n",
      "Stemming for there is there\n",
      "Stemming for , is ,\n",
      "Stemming for how is how\n",
      "Stemming for are is are\n",
      "Stemming for you is you\n",
      "Stemming for ? is ?\n",
      "Stemming for Weather is weather\n",
      "Stemming for is is is\n",
      "Stemming for awesome is awesom\n",
      "Stemming for . is .\n",
      "Stemming for Its is it\n",
      "Stemming for raining is rain\n",
      "Stemming for here is here\n",
      "Stemming for now is now\n",
      "Stemming for . is .\n",
      "Stemming for Hello is hello\n",
      "Stemming for Mr. is mr.\n",
      "Stemming for Raja is raja\n",
      "Stemming for , is ,\n",
      "Stemming for how is how\n",
      "Stemming for are is are\n",
      "Stemming for you is you\n",
      "Stemming for ? is ?\n",
      "Stemming for Weather is weather\n",
      "Stemming for is is is\n",
      "Stemming for awesome is awesom\n",
      "Stemming for . is .\n",
      "Stemming for Its is it\n",
      "Stemming for raining is rain\n",
      "Stemming for here is here\n",
      "Stemming for now is now\n",
      "Stemming for . is .\n",
      "Stemming for Hello is hello\n",
      "Stemming for Mr. is mr.\n",
      "Stemming for Raja is raja\n",
      "Stemming for , is ,\n",
      "Stemming for how is how\n",
      "Stemming for are is are\n",
      "Stemming for you is you\n",
      "Stemming for . is .\n",
      "Stemming for Weather is weather\n",
      "Stemming for is is is\n",
      "Stemming for bad is bad\n",
      "Stemming for . is .\n",
      "Stemming for Its is it\n",
      "Stemming for heavily is heavili\n",
      "Stemming for raining is rain\n",
      "Stemming for here is here\n",
      "Stemming for now is now\n",
      "Stemming for . is .\n",
      "Stemming for NLP is nlp\n",
      "Stemming for is is is\n",
      "Stemming for great is great\n",
      "Stemming for technique is techniqu\n",
      "Stemming for . is .\n",
      "Stemming for It is It\n",
      "Stemming for is is is\n",
      "Stemming for nice is nice\n",
      "Stemming for to is to\n",
      "Stemming for learn is learn\n",
      "Stemming for this is thi\n",
      "Stemming for technique is techniqu\n",
      "Stemming for . is .\n",
      "Stemming for AI is AI\n",
      "Stemming for is is is\n",
      "Stemming for making is make\n",
      "Stemming for difference is differ\n",
      "Stemming for in is in\n",
      "Stemming for this is thi\n",
      "Stemming for world is world\n",
      "Stemming for now is now\n",
      "Stemming for . is .\n",
      "Stemming for It is It\n",
      "Stemming for would is would\n",
      "Stemming for be is be\n",
      "Stemming for helpful is help\n",
      "Stemming for for is for\n",
      "Stemming for betterment is better\n",
      "Stemming for of is of\n",
      "Stemming for human is human\n",
      "Stemming for life is life\n",
      "Stemming for . is .\n",
      "Stemming for We is We\n",
      "Stemming for need is need\n",
      "Stemming for to is to\n",
      "Stemming for make is make\n",
      "Stemming for advantage is advantag\n",
      "Stemming for of is of\n",
      "Stemming for that is that\n",
      "Stemming for . is .\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer  = PorterStemmer()\n",
    "tokenization = nltk.word_tokenize(sentence)\n",
    "for w in tokenization:\n",
    "      print(\"Stemming for {} is {}\".format(w,porter_stemmer.stem(w))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma for Hello is Hello\n",
      "Lemma for there is there\n",
      "Lemma for , is ,\n",
      "Lemma for how is how\n",
      "Lemma for are is are\n",
      "Lemma for you is you\n",
      "Lemma for ? is ?\n",
      "Lemma for Weather is Weather\n",
      "Lemma for is is is\n",
      "Lemma for awesome is awesome\n",
      "Lemma for . is .\n",
      "Lemma for Its is Its\n",
      "Lemma for raining is raining\n",
      "Lemma for here is here\n",
      "Lemma for now is now\n",
      "Lemma for . is .\n",
      "Lemma for Hello is Hello\n",
      "Lemma for Mr. is Mr.\n",
      "Lemma for Raja is Raja\n",
      "Lemma for , is ,\n",
      "Lemma for how is how\n",
      "Lemma for are is are\n",
      "Lemma for you is you\n",
      "Lemma for ? is ?\n",
      "Lemma for Weather is Weather\n",
      "Lemma for is is is\n",
      "Lemma for awesome is awesome\n",
      "Lemma for . is .\n",
      "Lemma for Its is Its\n",
      "Lemma for raining is raining\n",
      "Lemma for here is here\n",
      "Lemma for now is now\n",
      "Lemma for . is .\n",
      "Lemma for Hello is Hello\n",
      "Lemma for Mr. is Mr.\n",
      "Lemma for Raja is Raja\n",
      "Lemma for , is ,\n",
      "Lemma for how is how\n",
      "Lemma for are is are\n",
      "Lemma for you is you\n",
      "Lemma for . is .\n",
      "Lemma for Weather is Weather\n",
      "Lemma for is is is\n",
      "Lemma for bad is bad\n",
      "Lemma for . is .\n",
      "Lemma for Its is Its\n",
      "Lemma for heavily is heavily\n",
      "Lemma for raining is raining\n",
      "Lemma for here is here\n",
      "Lemma for now is now\n",
      "Lemma for . is .\n",
      "Lemma for NLP is NLP\n",
      "Lemma for is is is\n",
      "Lemma for great is great\n",
      "Lemma for technique is technique\n",
      "Lemma for . is .\n",
      "Lemma for It is It\n",
      "Lemma for is is is\n",
      "Lemma for nice is nice\n",
      "Lemma for to is to\n",
      "Lemma for learn is learn\n",
      "Lemma for this is this\n",
      "Lemma for technique is technique\n",
      "Lemma for . is .\n",
      "Lemma for AI is AI\n",
      "Lemma for is is is\n",
      "Lemma for making is making\n",
      "Lemma for difference is difference\n",
      "Lemma for in is in\n",
      "Lemma for this is this\n",
      "Lemma for world is world\n",
      "Lemma for now is now\n",
      "Lemma for . is .\n",
      "Lemma for It is It\n",
      "Lemma for would is would\n",
      "Lemma for be is be\n",
      "Lemma for helpful is helpful\n",
      "Lemma for for is for\n",
      "Lemma for betterment is betterment\n",
      "Lemma for of is of\n",
      "Lemma for human is human\n",
      "Lemma for life is life\n",
      "Lemma for . is .\n",
      "Lemma for We is We\n",
      "Lemma for need is need\n",
      "Lemma for to is to\n",
      "Lemma for make is make\n",
      "Lemma for advantage is advantage\n",
      "Lemma for of is of\n",
      "Lemma for that is that\n",
      "Lemma for . is .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import \tWordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "tokenization = nltk.word_tokenize(sentence)\n",
    "for w in tokenization:\n",
    "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 5. Create a small dictionary file with required set of words with weightage attached to it with positive and negative numbers. Create a python script that analyzes the given text file and classify it as negative or positive sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose is beautiful.\n",
      "\n",
      "Place is nasty to stay.\n",
      "\n",
      "This is the beauty of this technique.\n",
      "\n",
      "Concept is explained beautifully in this book.\n",
      "\n",
      "He annoyed me.\n",
      "\n",
      "Its the supreme place to stay.\n",
      "\n",
      "I hate this place.\n",
      "\n",
      "Dont annoy the customer.\n",
      "\n",
      "He has given nasty comments about his stay.\n",
      "\n",
      "Dessert is awesome.\n",
      "\n",
      "Your gift is wonderful.\n"
     ]
    }
   ],
   "source": [
    "with open('d://data_senti_analyze.txt') as e:\n",
    "    for line in e:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Rose is beautiful.\n",
    "\n",
    "Place is nasty to stay.\n",
    "\n",
    "This is the beauty of this technique.\n",
    "\n",
    "Concept is explained beautifully in this book.\n",
    "\n",
    "He annoyed me.\n",
    "\n",
    "Its the supreme place to stay.\n",
    "\n",
    "I hate this place.\n",
    "\n",
    "Dont annoy the customer.\n",
    "\n",
    "He has given nasty comments about his stay.\n",
    "\n",
    "Dessert is awesome.\n",
    "\n",
    "Your gift is wonderful.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = SI.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: 0.9393, neg: 0.163, neu: 0.496, pos: 0.34, "
     ]
    }
   ],
   "source": [
    "for key in sorted(scores):\n",
    "        print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
